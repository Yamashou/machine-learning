{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. import libraries\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './out/'\n",
    "prefix = 'vgg16'\n",
    "n_train_samples = 2000\n",
    "train_file_name = 'bottleneck_features_train.npy'\n",
    "\n",
    "n_validation_samples = 800\n",
    "validation_file_name = 'bottleneck_features_validation.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1-1.Create Bottleneck Features data from image data\n",
    "\n",
    "# Load VGG16 model & weight\n",
    "model = VGG16(include_top=False, weights='imagenet')\n",
    "model.summary()\n",
    "\n",
    "# convert image data into numpy array using imageDataGenerator\n",
    "## training data\n",
    "image_data_generator = ImageDataGenerator(rescale=1.0/255)\n",
    "train_data = image_data_generator.flow_from_directory(\n",
    "    'dataset/trainData',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "## validation data \n",
    "image_data_generator = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_data = image_data_generator.flow_from_directory(\n",
    "    'dataset/validationData',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate bottleneck featuresata using VGG16\n",
    "## training data\n",
    "bottleneck_feature_train = model.predict_generator(train_data, n_train_samples, verbose=1)\n",
    "\n",
    "## validation data \n",
    "bottleneck_feature_validation = model.predict_generator(validation_data, n_validation_samples, verbose=1)\n",
    "\n",
    "# Save bottleneck features training data\n",
    "## traning data\n",
    "np.save(base_dir + prefix + train_file_name, bottleneck_feature_train)\n",
    "\n",
    "## validation data\n",
    "np.save(base_dir + prefix + validation_file_name, bottleneck_feature_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2. Load Existing Bottleneck features data \n",
    "train_data  = np.load(base_dir + prefix + train_file_name)\n",
    "len_input_samples = len(train_data)\n",
    "train_labels = np.array([0] * int(len_input_samples/2) + [1] * int(len_input_samples / 2))\n",
    "\n",
    "validation_data = np.load(base_dir + prefix + validation_file_name)\n",
    "validation_labels = np.array([0] * int(n_validation_samples / 2 *32) + [1] * int(n_validation_samples / 2 * 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Create Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "input_shape = train_data.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Train Model \n",
    "result_dir =  './out/history_vgg16_transfer_learning.txt'\n",
    "\n",
    "# callbacks\n",
    "callbacks = keras.callbacks.TensorBoard(log_dir='./out/tensorBoard', histogram_freq=0)\n",
    "\n",
    "# train model\n",
    "history = model.fit(train_data, train_labels, epochs=20, batch_size=32, callbacks=[callbacks], validation_data=(validation_data, validation_labels))\n",
    "\n",
    "# Save weight\n",
    "model.save_weights('./out/vgg16_transferlearning_weights.h5')\n",
    "\n",
    "# Save history\n",
    "loss = history.history['loss']\n",
    "acc = history.history['acc']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "with open(result_dir, \"w\") as fp:\n",
    "    fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
    "    for i in range(len(acc)):\n",
    "        fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" % (i, loss[i], acc[i], val_loss[i], val_acc[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
